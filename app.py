import streamlit as st
import yfinance as yf
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import google.generativeai as genai
import requests
from datetime import datetime, timedelta

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="ì§€ëŠ¥í˜• ì£¼ì‹ ë¸”ë¡œê·¸ ë¹„ì„œ (Gemini)",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS ë° ìŠ¤íƒ€ì¼ë§ ---
st.markdown("""
<style>
    .reportview-container {
        background: #0e1117;
    }
    .main .block-container {
        padding-top: 2rem;
    }
    h1, h2, h3 {
        font-family: 'Sans-serif';
    }
    .stMetric {
        background-color: #262730;
        padding: 10px;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.header("ì„¤ì • ë° ì…ë ¥")
    
    # Google API í‚¤ ì…ë ¥
    if 'GOOGLE_API_KEY' in st.secrets.get('general', {}):
        api_key = st.secrets['general']['GOOGLE_API_KEY']
        st.success("Gemini API í‚¤ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        api_key = st.text_input("Google API Key", type="password", help="AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.caption("íŒ: .streamlit/secrets.toml íŒŒì¼ì— í‚¤ë¥¼ ì €ì¥í•˜ì„¸ìš”.")
    
    st.markdown("---")
    st.header("ì¢…ëª© ê²€ìƒ‰")
    ticker_symbol = st.text_input("í‹°ì»¤ ì…ë ¥ (ì˜ˆ: NVDA, AAPL)", value="NVDA").upper()
    
    if st.button("ë¶„ì„ ì‹œì‘"):
        st.session_state['run_analysis'] = True
    else:
        if 'run_analysis' not in st.session_state:
            st.session_state['run_analysis'] = False

# --- ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í†µí•© í•¨ìˆ˜ ---
from duckduckgo_search import DDGS
from difflib import SequenceMatcher

def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()

# í•œêµ­ì–´ ë²ˆì—­ í—¬í¼ í•¨ìˆ˜
def translate_to_korean(text):
    try:
        from deep_translator import GoogleTranslator
        return GoogleTranslator(source='auto', target='ko').translate(text)
    except:
        return text

# ê¸°ì—… ëŒ€í‘œ ì´ë¯¸ì§€ ê²€ìƒ‰ í•¨ìˆ˜ - í•µì‹¬ ë§¤ì¶œ ì œí’ˆ ê¸°ë°˜
def get_company_images(ticker, company_name="", industry=""):
    """DuckDuckGo ì´ë¯¸ì§€ ê²€ìƒ‰ìœ¼ë¡œ ê¸°ì—… í•µì‹¬ ì œí’ˆ ì´ë¯¸ì§€ 4ì¥ ê°€ì ¸ì˜¤ê¸°"""
    images = []
    
    # í‹°ì»¤ë³„ í•µì‹¬ ì œí’ˆ í‚¤ì›Œë“œ ë§¤í•‘
    product_keywords = {
        'NVDA': 'data center GPU AI chip H100',
        'AAPL': 'iPhone MacBook Apple products',
        'MSFT': 'Azure cloud Microsoft Office',
        'GOOGL': 'Google Search AI Cloud',
        'GOOG': 'Google Search AI Cloud',
        'AMZN': 'AWS cloud Amazon warehouse',
        'META': 'Facebook Instagram VR Quest',
        'TSLA': 'Tesla Model electric car',
        'AMD': 'AMD EPYC Ryzen processor',
        'INTC': 'Intel processor data center',
    }
    
    try:
        with DDGS() as ddgs:
            # í‹°ì»¤ì— ë§ëŠ” í‚¤ì›Œë“œ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            keyword = product_keywords.get(ticker, f"{company_name} main product")
            query = f"{keyword}"
            
            results = list(ddgs.images(query, max_results=4))
            for r in results:
                images.append({
                    'url': r.get('image', ''),
                    'title': r.get('title', ''),
                    'source': r.get('source', '')
                })
    except Exception as e:
        print(f"Image search error: {e}")
    
    return images


def get_hybrid_news(ticker):
    news_items = []
    
    # 1. DuckDuckGo Search (ê¸ˆìœµ ë¯¸ë””ì–´ íƒ€ê²Ÿ)
    target_sites = [
        ('CNBC', 'site:cnbc.com'),
        ('Reuters', 'site:reuters.com'),
        ('Investing.com', 'site:investing.com'),
        ('Bloomberg', 'site:bloomberg.com')
    ]
    
    try:
        with DDGS() as ddgs:
            for source_name, site_query in target_sites:
                query = f"{ticker} stock news {site_query}"
                results = list(ddgs.text(query, max_results=2))
                for r in results:
                    news_items.append({
                        'title': r['title'],
                        'link': r['href'],
                        'publisher': source_name,
                        'date': datetime.now().isoformat()
                    })
    except Exception as e:
        print(f"DDGS Error: {e}")

    # 2. Yahoo Finance News
    try:
        stock = yf.Ticker(ticker)
        yf_news = stock.news[:5]
        for item in yf_news:
            news_items.append({
                'title': item.get('title'),
                'link': item.get('link'),
                'publisher': 'Yahoo Finance',
                'date': str(item.get('providerPublishTime', ''))
            })
    except Exception as e:
        print(f"Yahoo News Error: {e}")

    # 3. Google News RSS (ê°€ì¥ ì•ˆì •ì ì¸ ì†ŒìŠ¤)
    try:
        import xml.etree.ElementTree as ET
        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        resp = requests.get(url, timeout=10)
        if resp.status_code == 200:
            root = ET.fromstring(resp.content)
            for item in root.findall('.//item')[:5]:
                title_raw = item.find('title').text if item.find('title') is not None else 'No Title'
                parts = title_raw.rsplit(' - ', 1)
                title = parts[0].strip()
                publisher = parts[1].strip() if len(parts) > 1 else 'Google News'
                
                # Google News ë¦¬ë‹¤ì´ë ‰íŠ¸ ë§í¬ì—ì„œ ì‹¤ì œ URL ì¶”ì¶œ
                google_link = item.find('link').text if item.find('link') is not None else '#'
                try:
                    # ë¦¬ë‹¤ì´ë ‰íŠ¸ë¥¼ ë”°ë¼ê°€ì„œ ì‹¤ì œ URL ê°€ì ¸ì˜¤ê¸°
                    redirect_resp = requests.head(google_link, allow_redirects=True, timeout=5)
                    actual_link = redirect_resp.url
                except:
                    actual_link = google_link
                
                pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ''
                date_str = pub_date[:16] if pub_date else datetime.now().strftime('%Y-%m-%d')
                
                news_items.append({
                    'title': title,
                    'link': actual_link,
                    'publisher': publisher,
                    'date': date_str
                })
    except Exception as e:
        print(f"Google RSS Error: {e}")


    # 4. ì¤‘ë³µ ì œê±° (ì œëª© ìœ ì‚¬ë„ 80% ì´ìƒ)
    unique_news = []
    for item in news_items:
        if not item.get('title'): continue
        is_duplicate = False
        for existing in unique_news:
            if similar(item['title'].lower(), existing['title'].lower()) > 0.8:
                is_duplicate = True
                break
        if not is_duplicate:
            unique_news.append(item)
    
    # 5. ë‰´ìŠ¤ ì œëª© í•œêµ­ì–´ ë²ˆì—­ + ëŒ€í‘œ ì´ë¯¸ì§€ ì¶”ì¶œ
    for item in unique_news:
        original_title = item.get('title', '')
        item['title_en'] = original_title
        item['title'] = translate_to_korean(original_title)
        
        # og:image ì¶”ì¶œ ì‹œë„
        try:
            from bs4 import BeautifulSoup
            resp = requests.get(item.get('link', ''), timeout=5, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, 'html.parser')
                og_image = soup.find('meta', property='og:image')
                if og_image and og_image.get('content'):
                    item['image_url'] = og_image['content']
                else:
                    item['image_url'] = ''
            else:
                item['image_url'] = ''
        except:
            item['image_url'] = ''
            
    return unique_news[:10]

@st.cache_data
def get_dashboard_data(ticker):
    """ì£¼ê°€, ì •ë³´, ë‰´ìŠ¤ë¥¼ í•œ ë²ˆì— ê°€ì ¸ì™€ì„œ serializableí•œ í˜•íƒœë¡œ ë°˜í™˜"""
    df = None
    error_msg = None
    
    # 1. ì£¼ê°€ ë°ì´í„°
    try:
        df = yf.download(ticker, period="1y", progress=False)
        
        # yfinanceê°€ MultiIndex ì»¬ëŸ¼ì„ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í‰íƒ„í™”
        if df is not None and not df.empty:
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
        
        if df is None or df.empty:
            try:
                import pandas_datareader.data as web
                start = datetime.now() - timedelta(days=365)
                end = datetime.now()
                try:
                    df = web.DataReader(f"{ticker}.US", 'stooq', start, end).sort_index()
                except:
                    df = web.DataReader(ticker, 'stooq', start, end).sort_index()
            except Exception as e:
                error_msg = f"ë°ì´í„° ìˆ˜ì‹  ì‹¤íŒ¨: {str(e)}"
        
        if df is not None and df.empty:
            error_msg = "ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
    except Exception as e:
        error_msg = f"ì˜¤ë¥˜: {str(e)}"
    
    # 2. ìƒì„¸ ì •ë³´
    info = {}
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
    except:
        info = {}
    
    # 3. ë‰´ìŠ¤ (Hybrid ë°©ì‹)
    news = get_hybrid_news(ticker)

    return df, info, news, error_msg

# --- AI ë¶„ì„ ìš”ì²­ í•¨ìˆ˜ (Gemini 1 -> Gemini 2 -> Groq ìˆœì°¨ ì‹œë„) ---
def generate_ai_analysis(ticker, df_summary, news_summary, image_list, api_key):
    # ì—¬ëŸ¬ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    gemini_key_1 = st.secrets.get('general', {}).get('GOOGLE_API_KEY_1', api_key)
    gemini_key_2 = st.secrets.get('general', {}).get('GOOGLE_API_KEY_2', '')
    groq_key = st.secrets.get('general', {}).get('GROQ_API_KEY', '')
    
    if not gemini_key_1 and not api_key:
        return "API í‚¤ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ í¬ë§·íŒ…
    images_str = ""
    if image_list:
        images_str = "\n[ì‚¬ìš© ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ëª©ë¡ - ì´ ì¤‘ ì ì ˆí•œ ê²ƒì„ ê³¨ë¼ ê¸€ ë‚´ìš© ì¤‘ê°„ì— ë§ˆí¬ë‹¤ìš´ ![](url) ìœ¼ë¡œ ì‚½ì…í•˜ì„¸ìš”]\n"
        for i, img in enumerate(image_list):
            images_str += f"{i+1}. {img['title']} (URL: {img['url']})\n"
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ì˜ íˆ¬ì ë¶„ì„ ë¸”ë¡œê±°ì…ë‹ˆë‹¤.
    
    '{ticker}' ì£¼ì‹ì— ëŒ€í•´ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ì°¸ê³  ë°ì´í„°]
    ì£¼ê°€ ì •ë³´: {df_summary}
    ìµœê·¼ ë‰´ìŠ¤: {news_summary}
    {images_str}

    
    [ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼ - ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]
    
    1. ëª¨ë“  ë¬¸ì¥ ëì— ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ 2ë²ˆ (ë¹ˆ ì¤„ ì‚½ì…)
    2. ì ˆëŒ€ë¡œ ë‘ ë¬¸ì¥ì„ í•œ ì¤„ì— ì“°ì§€ ì•ŠìŒ
    3. í•œ ë¬¸ì¥ì€ 30~50ì, í•µì‹¬ë§Œ
    4. "~ì´ë‹¤", "~í–ˆë‹¤" ê°„ê²°ì²´ ì‚¬ìš©
    5. ì´ëª¨ì§€, íŠ¹ìˆ˜ë¬¸ì ê¸ˆì§€
    6. ë‰´ìŠ¤ ì¸ìš© ì‹œ ì¶œì²˜ì™€ ë‚ ì§œ ëª…ì‹œ
    
    [ì¤„ë°”ê¿ˆ ì˜ˆì‹œ - ë°˜ë“œì‹œ ì´ í˜•ì‹ìœ¼ë¡œ]
    
    ì²« ë²ˆì§¸ ë¬¸ì¥ì´ë‹¤.
    
    ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ë‹¤.
    
    ì„¸ ë²ˆì§¸ ë¬¸ì¥ì´ë‹¤.
    
    [í•„ìˆ˜ í¬í•¨ ë‚´ìš© - ì œëª© ì—†ì´ ë‚´ìš©ë§Œ]
    
    ë¨¼ì € ì´ íšŒì‚¬ì˜ ì£¼ìš” ì‚¬ì—… ë¶€ë¬¸ë³„ ë§¤ì¶œ ë¹„ì¤‘ì„ êµ¬ì²´ì  ìˆ«ì(%)ë¡œ ì œì‹œí•œë‹¤.
    í˜„ì¬ ê°€ì¥ í° ë§¤ì¶œì›ì´ ì–´ë””ì¸ì§€, í–¥í›„ ì„±ì¥ì´ ê¸°ëŒ€ë˜ëŠ” ë¶€ë¬¸ì€ ì–´ë””ì¸ì§€ ì„¤ëª…í•œë‹¤.
    
    ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    
    í˜„ì¬ ì£¼ê°€ì™€ 52ì£¼ ìµœê³ /ìµœì € ë¹„êµ, 1ë…„ ìˆ˜ìµë¥ ê³¼ ìµœê·¼ íë¦„ì„ ì„¤ëª…í•œë‹¤.
    
    ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    
    ì£¼ìš” ë‰´ìŠ¤ 2-3ê°œë¥¼ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¸ìš©í•œë‹¤:
    "ë‰´ìŠ¤ ì œëª©" (ì¶œì²˜: ë§¤ì²´ëª…, ê¸°ì‚¬ë§í¬: URL)
    
    ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    
    í•µì‹¬ íˆ¬ì í¬ì¸íŠ¸ 2-3ê°œì™€ ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸ 2-3ê°œë¥¼ ë‚˜ì—´í•œë‹¤.
    
    ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡
    
    í˜„ì¬ ì´ ì¢…ëª©ì— ëŒ€í•œ ì¢…í•© ì˜ê²¬ 1-2ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œë‹¤.
    (íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹Œ ì •ë³´ ê³µìœ  ëª©ì ì„ì„ ëª…ì‹œ)
    
    [ì¤‘ìš”: í˜•ì‹ ê·œì¹™]
    - "##" ê°™ì€ ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°í˜¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    - ì œëª© ëŒ€ì‹  ìœ„ì²˜ëŸ¼ "ã…¡ã…¡ã…¡ã…¡ã…¡" êµ¬ë¶„ì„ ìœ¼ë¡œ ì„¹ì…˜ì„ ë‚˜ëˆ”
    
    ì´ 50ë¬¸ì¥ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ì‘ì„±.
    """
    
    # 1. Gemini í‚¤ 1 ì‹œë„
    try:
        genai.configure(api_key=gemini_key_1)
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e1:
        if "429" not in str(e1):
            return f"AI ì˜¤ë¥˜: {str(e1)}"
    
    # 2. Gemini í‚¤ 2 ì‹œë„
    if gemini_key_2:
        try:
            genai.configure(api_key=gemini_key_2)
            model = genai.GenerativeModel('gemini-2.5-flash')
            response = model.generate_content(prompt)
            return f"[Gemini í‚¤2 ì‚¬ìš©]\n\n{response.text}"
        except Exception as e2:
            if "429" not in str(e2):
                return f"AI ì˜¤ë¥˜: {str(e2)}"
    
    # 3. Groqë¡œ fallback
    if groq_key:
        try:
            from groq import Groq
            client = Groq(api_key=groq_key)
            
            chat_completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì˜ íˆ¬ì ë¶„ì„ ë¸”ë¡œê±°ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                model="llama-3.3-70b-versatile",
                temperature=0.7,
                max_tokens=2000
            )
            
            return f"[Groq AI ì‚¬ìš©]\n\n{chat_completion.choices[0].message.content}"
        except Exception as e3:
            return f"ëª¨ë“  AI ì„œë¹„ìŠ¤ ì‹¤íŒ¨: {str(e3)}"
    
    return "ëª¨ë“  API ì œí•œ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."



#------ ë©”ì¸ ì•± ë¡œì§ ------

st.title("ì§€ëŠ¥í˜• ì£¼ì‹ ë¸”ë¡œê·¸ ë¹„ì„œ")
st.markdown("ì£¼ê°€ ë°ì´í„° ì‹œê°í™”, ë‰´ìŠ¤ ë¶„ì„, ê·¸ë¦¬ê³  AI ê¸°ë°˜ì˜ ë¯¸ë˜ ì „ë§ ë¦¬í¬íŠ¸ê¹Œì§€ í•œ ë²ˆì— í™•ì¸í•˜ì„¸ìš”.")

if st.session_state['run_analysis'] and ticker_symbol:
    
    # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    with st.spinner(f"'{ticker_symbol}' ë°ì´í„° ê²€ìƒ‰ ë° ë¶„ì„ ì¤€ë¹„ ì¤‘..."):
        df, info, news_list, error_msg = get_dashboard_data(ticker_symbol)
    
    # ì—ëŸ¬ ê²½ê³  (ìˆìœ¼ë©´)
    if error_msg:
        st.warning(f"ì£¼ê°€ ë°ì´í„°: {error_msg}")
    
    # ì‚¬ì´ë“œë°” ì •ë³´
    with st.sidebar:
        st.markdown("---")
        st.subheader(f"{ticker_symbol} ì£¼ìš” ì§€í‘œ")
        if info and info.get('currentPrice'):
            current_price = info.get('currentPrice', info.get('regularMarketPrice', 'N/A'))
            market_cap = info.get('marketCap', 'N/A')
            per = info.get('trailingPE', 'N/A')
            
            def format_num(num):
                if isinstance(num, (int, float)):
                    return f"{num:,.0f}"
                return num
            
            st.metric("í˜„ì¬ ì£¼ê°€", f"${current_price}")
            st.write(f"**ì‹œê°€ì´ì•¡**: {format_num(market_cap)}")
            st.write(f"**PER**: {per}")
        else:
            st.caption("ì¬ë¬´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ê¸°ì—… ëŒ€í‘œ ì´ë¯¸ì§€ ì„¹ì…˜
    company_name = info.get('longName', info.get('shortName', ticker_symbol))
    company_images = get_company_images(ticker_symbol, company_name)
    
    if company_images:
        st.subheader(f"{ticker_symbol} ê¸°ì—… ì´ë¯¸ì§€")
        img_cols = st.columns(4)
        for idx, img in enumerate(company_images[:4]):
            with img_cols[idx]:
                if img.get('url'):
                    st.image(img['url'], caption=img.get('source', ''), use_container_width=True)
                    st.caption(f"[ì´ë¯¸ì§€ ë§í¬]({img['url']})")

    # ì°¨íŠ¸ ì‹œê°í™” (ë°ì´í„° ìˆì„ ë•Œë§Œ)
    if df is not None and not df.empty and len(df) > 0:
        st.subheader(f"{ticker_symbol} ì£¼ê°€ ë° ê±°ë˜ëŸ‰ ì°¨íŠ¸ (ì§€ë‚œ 1ë…„)")
        
        # ì´ë™í‰ê· ì„ 
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['MA60'] = df['Close'].rolling(window=60).mean()
        
        # ì°¨íŠ¸ ìƒì„±
        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, 
                            vertical_spacing=0.03, 
                            subplot_titles=(f'{ticker_symbol} Price Chart', 'Volume'), 
                            row_heights=[0.7, 0.3])
        
        # ìº”ë“¤ìŠ¤í‹±
        fig.add_trace(go.Candlestick(
            x=df.index,
            open=df['Open'], 
            high=df['High'],
            low=df['Low'], 
            close=df['Close'], 
            name='OHLC'
        ), row=1, col=1)
        
        # ì´ë™í‰ê· ì„ 
        fig.add_trace(go.Scatter(
            x=df.index, y=df['MA20'], 
            opacity=0.7, 
            line=dict(color='orange', width=2), 
            name='MA 20'
        ), row=1, col=1)
        
        fig.add_trace(go.Scatter(
            x=df.index, y=df['MA60'], 
            opacity=0.7, 
            line=dict(color='purple', width=2), 
            name='MA 60'
        ), row=1, col=1)
        
        # ê±°ë˜ëŸ‰ (ìƒ‰ìƒ: í•˜ë½=red, ìƒìŠ¹=green)
        import numpy as np
        colors = np.where(df['Close'].values < df['Open'].values, 'red', 'green')
        fig.add_trace(go.Bar(
            x=df.index, 
            y=df['Volume'], 
            marker_color=colors, 
            name='Volume'
        ), row=2, col=1)
        
        fig.update_layout(
            height=600, 
            showlegend=True, 
            xaxis_rangeslider_visible=False,
            title_text=f"{ticker_symbol} Analysis Chart"
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë‰´ìŠ¤ ë° AI ë¶„ì„
    col1, col2 = st.columns([1, 1])
    news_summary_text = ""
    
    with col1:
        st.subheader("ìµœì‹  ë‰´ìŠ¤")
        
        if not news_list:
            st.info("ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            news_summary_text = "ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ"
        else:
            for idx, item in enumerate(news_list):
                title = item.get('title', 'ì œëª© ì—†ìŒ')
                link = item.get('link', '#')
                publisher = item.get('publisher', 'Unknown')
                date = item.get('date', '')
                image_url = item.get('image_url', '')
                
                st.markdown(f"**{idx+1}. [{title}]({link})**")
                if image_url:
                    st.caption(f"ì¶œì²˜: {publisher} | ë‚ ì§œ: {date}")
                    st.caption(f"ì´ë¯¸ì§€: {image_url}")
                else:
                    st.caption(f"ì¶œì²˜: {publisher} | ë‚ ì§œ: {date}")
                
                # AIìš© ë‰´ìŠ¤ ìš”ì•½ì— ì´ë¯¸ì§€ URL í¬í•¨
                news_summary_text += f"- {title} (ì¶œì²˜: {publisher}, ë‚ ì§œ: {date}, ê¸°ì‚¬ë§í¬: {link}"
                if image_url:
                    news_summary_text += f", ì´ë¯¸ì§€URL: {image_url}"
                news_summary_text += ")\n"

    
    with col2:
        st.subheader("AI íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸")
        
        # ë°ì´í„° ìš”ì•½
        if df is not None and not df.empty and len(df) > 0:
            last_close = float(df['Close'].iloc[-1])
            first_close = float(df['Close'].iloc[0])
            high_max = float(df['High'].max())
            low_min = float(df['Low'].min())
            price_change_1y = ((last_close - first_close) / first_close) * 100
            data_summary = f"""
            - ì¢…ëª©: {ticker_symbol}
            - í˜„ì¬ ì£¼ê°€: ${last_close:.2f}
            - 1ë…„ ìˆ˜ìµë¥ : {price_change_1y:.2f}%
            - 52ì£¼ ìµœê³ ê°€: ${high_max:.2f}
            - 52ì£¼ ìµœì €ê°€: ${low_min:.2f}
            """
        else:
            data_summary = f"- ì¢…ëª©: {ticker_symbol}\n- ì£¼ê°€ ë°ì´í„°: ìˆ˜ì‹  ì‹¤íŒ¨"
        
        # AI ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
        ai_image_list = []
        
        # 1. ê¸°ì—… ëŒ€í‘œ ì´ë¯¸ì§€
        if company_images:
            for img in company_images:
                if img.get('url'):
                    ai_image_list.append({'title': f"{ticker_symbol} ê´€ë ¨ ì´ë¯¸ì§€", 'url': img['url']})
        
        # 2. ë‰´ìŠ¤ ì´ë¯¸ì§€
        for item in news_list:
            if item.get('image_url'):
                ai_image_list.append({'title': f"ë‰´ìŠ¤ ì´ë¯¸ì§€: {item.get('title')}", 'url': item.get('image_url')})

        # AI ë¶„ì„ ìƒì„±
        with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê¸€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # API í‚¤ (ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ í‚¤ ì „ë‹¬)
            api_key = st.secrets.get('general', {}).get('GOOGLE_API_KEY_1', st.session_state.get('api_key', ''))
            
            ai_report = generate_ai_analysis(ticker_symbol, data_summary, news_summary_text, ai_image_list, api_key)

        
        st.markdown(ai_report)
        st.text_area("ë¸”ë¡œê·¸ í¬ìŠ¤íŒ…ìš© í…ìŠ¤íŠ¸ ë³µì‚¬", value=ai_report, height=200)

else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì£¼ì‹ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
